### Compute Aware AI Systems 

##### CPU
 commonly used for data processing, model development, and scalable inference. Handle diverse tasks throughout the ML pipeline. 

##### GPU
 generally used in AI workloads to accelerate compute-intensive tasks, leveraging their parallel architeccture and optimized floating point operations for faster and more efficient computations. Using GPU's can enhance the training and inference processes of AI models. 


- Clusters 
- FPGA's 
- EDGE 